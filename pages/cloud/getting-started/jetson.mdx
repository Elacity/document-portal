import { Callout } from 'nextra/components'

# NVIDIA Jetson

Run PC2 on an NVIDIA Jetson for GPU-accelerated private AI. Your Jetson becomes a sovereign AI node — running local language models with hardware acceleration, entirely on your hardware.

<Callout type="info">
**Why Jetson?** Dedicated NVIDIA GPUs accelerate AI inference 3-10x faster than CPU-only. Faster responses from your local AI agent, completely private.
</Callout>

## Supported Devices

| Model | RAM | GPU | AI Performance | Price |
|-------|-----|-----|----------------|-------|
| **Jetson Nano (4GB)** | 4GB | 128 CUDA cores | Entry-level | ~$150 |
| **Jetson Orin Nano** | 8GB | 1024 CUDA cores | Mid-range (recommended) | ~$250 |
| **Jetson Orin NX** | 16GB | 2048 CUDA cores | High-end | ~$900 |
| **Jetson AGX Orin** | 64GB | 2048 CUDA cores | Enterprise | ~$2000 |

## Step 1: Free Up RAM (Recommended)

Your Jetson ships with a GNOME desktop that uses 1-2GB of RAM. Since PC2 provides its own web interface, remove it to free that RAM for AI:

```bash
sudo systemctl set-default multi-user.target
sudo apt remove --purge -y ubuntu-desktop gnome-shell gdm3
sudo apt autoremove -y
sudo reboot
```

After reboot, SSH in from another computer:

```bash
ssh your-username@your-jetson-ip
```

<Callout type="info">
Find your Jetson's IP before removing the desktop: run `hostname -I`
</Callout>

## Step 2: Install PC2

One command. This installs everything — Node.js, dependencies, build tools, and starts the server:

```bash
curl -fsSL https://raw.githubusercontent.com/Elacity/pc2.net/main/scripts/start-local.sh | bash
```

Once complete, open **http://your-jetson-ip:4200** in a browser on any device on your network. Connect your wallet and pick a username.

<Callout type="info">
**Remote Access**: Your Jetson automatically registers a `username.ela.city` domain through the Boson network. Anyone can reach your PC2 at `https://username.ela.city` — even behind your home router.
</Callout>

## Step 3: Install Ollama for Local AI (Optional)

To run AI models locally on your Jetson's GPU:

```bash
curl -fsSL https://ollama.com/install.sh | sh
```

Then pull a model based on your RAM:

```bash
# Jetson Nano (4GB)
ollama pull deepseek-r1:1.5b

# Jetson Orin (8GB+)
ollama pull llama3.2:3b

# Jetson Orin NX/AGX (16GB+)
ollama pull mistral:7b
```

Ollama automatically detects CUDA on Jetson. No extra GPU setup needed.

## Managing PC2

```bash
pm2 status          # Check if running
pm2 logs pc2        # View logs
pm2 restart pc2     # Restart
pm2 stop pc2        # Stop
```

### Auto-Start on Boot

```bash
pm2 startup         # Follow the printed command
pm2 save            # Save current process list
```

### Update PC2

```bash
pm2 stop pc2 && cd ~/pc2.net && git pull origin main && cd pc2-node && npm run build && pm2 restart pc2
```

## Performance Tips

### Use NVMe SSD

SD cards are slow. Install an M.2 NVMe SSD and flash JetPack directly to it for much better performance.

### Max Performance Mode

```bash
sudo nvpmodel -m 0     # Maximum performance (Orin)
sudo jetson_clocks      # Max clock speeds
```

### Increase Swap (for larger AI models)

```bash
sudo fallocate -l 4G /swapfile
sudo chmod 600 /swapfile
sudo mkswap /swapfile
sudo swapon /swapfile
echo '/swapfile none swap sw 0 0' | sudo tee -a /etc/fstab
```

### Monitor GPU

```bash
sudo pip3 install jetson-stats
sudo jtop
```

## Troubleshooting

**Ollama not using GPU?** Run `nvcc --version`. If not found: `sudo apt install -y nvidia-jetpack` then `sudo systemctl restart ollama`.

**Out of memory?** Remove the desktop (Step 1), use a smaller model, increase swap, disable bluetooth: `sudo systemctl disable bluetooth`.

**Can't access from browser?** Check `pm2 status`, try `curl http://localhost:4200/health`, open firewall: `sudo ufw allow 4200`.

**`wasm streaming compile failed` in logs?** Harmless — falls back automatically.

---

**Your hardware. Your AI. Your sovereignty.**
